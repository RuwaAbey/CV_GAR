{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO0UfeH4OufUj7TwgoKuJd/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RuwaAbey/Finaly_Year_Project_G09/blob/main/Mutual_action_dataset_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6OfMyOlm6tCU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjyfK6ZJ6wxs",
        "outputId": "3ebfcfb3-e3c5-4008-8c7c-cb7cc9ff4d0e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n",
            "True\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mmcv==1.5.0\n",
        "!pip install fvcore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa44LFJi6yER",
        "outputId": "0aae966a-e633-415c-b63f-e9bbea43fdb3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mmcv==1.5.0\n",
            "  Downloading mmcv-1.5.0.tar.gz (530 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/530.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/530.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m530.7/530.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict (from mmcv==1.5.0)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmcv==1.5.0) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mmcv==1.5.0) (24.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from mmcv==1.5.0) (11.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from mmcv==1.5.0) (6.0.2)\n",
            "Collecting yapf (from mmcv==1.5.0)\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->mmcv==1.5.0) (4.3.6)\n",
            "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading yapf-0.43.0-py3-none-any.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: mmcv\n",
            "  Building wheel for mmcv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmcv: filename=mmcv-1.5.0-py2.py3-none-any.whl size=807159 sha256=45c8b81641376451b5bd0c2a5327807a6f3bf4a3fa27ff413f3a8238998078c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/5f/a9/54775baf3e918cd5f286a769399f29d40ed5ae2a9a52811138\n",
            "Successfully built mmcv\n",
            "Installing collected packages: addict, yapf, mmcv\n",
            "Successfully installed addict-2.4.0 mmcv-1.5.0 yapf-0.43.0\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (1.26.4)\n",
            "Collecting yacs>=0.1.6 (from fvcore)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (2.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore) (11.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\n",
            "Collecting iopath>=0.1.7 (from fvcore)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (4.12.2)\n",
            "Collecting portalocker (from iopath>=0.1.7->fvcore)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=97cef666d6434ff4d74c482e35c76fb9ff3a5cc0ff7c4c42e01a6299b28f88e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31528 sha256=d5362facdec085e16a18dca44b66436c0ef5e89990881bd94231f5286ed6a766\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.1.1 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ55OuE06zcR",
        "outputId": "c44341a7-ecd6-476a-d26f-ad2597b2bcfe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My\\ Drive/G_09"
      ],
      "metadata": {
        "id": "AjQ2LySs6_wk",
        "outputId": "5b8f934a-d217-406a-a545-3008557d9d02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/G_09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kennymckormick/pyskl.git"
      ],
      "metadata": {
        "id": "gH6dcFn67BQJ",
        "outputId": "f66170f0-5436-4a06-b4be-7f75a8d6cfcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'pyskl' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My\\ Drive/G_09/pyskl"
      ],
      "metadata": {
        "id": "-I6_PXnM7FgJ",
        "outputId": "023e6f4a-f437-4208-ca02-aeb82adbc70b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/G_09/pyskl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyskl\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "peRZeLAr7MW1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "%cd /content/drive/My\\ Drive/G_09\n",
        "\n",
        "# Load the pickle file\n",
        "with open('ntu60_hrnet.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "# Check the top-level keys\n",
        "print(data.keys())  # Should print: ['split', 'annotations']"
      ],
      "metadata": {
        "id": "31abyXiV7NpA",
        "outputId": "4e805c96-0785-4bd1-8a3b-9badbbeecf8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/G_09\n",
            "dict_keys(['split', 'annotations'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "annotations = data['annotations']\n",
        "\n",
        "for annotation in annotations:\n",
        "    if annotation['frame_dir'] == 'S001C001P001R001A059':\n",
        "        action_58_sample = annotation\n",
        "        print(annotation)"
      ],
      "metadata": {
        "id": "k9zSRFo97oKB",
        "outputId": "e08198d1-2df9-47aa-8ae5-4b2fcab27d64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'frame_dir': 'S001C001P001R001A059', 'label': 58, 'img_shape': (1080, 1920), 'original_shape': (1080, 1920), 'total_frames': 99, 'keypoint': array([[[[1433. ,  321. ],\n",
            "         [1441. ,  312.5],\n",
            "         [1429. ,  312.5],\n",
            "         ...,\n",
            "         [1425. ,  588.5],\n",
            "         [1450. ,  676. ],\n",
            "         [1425. ,  668. ]],\n",
            "\n",
            "        [[1431. ,  323.2],\n",
            "         [1439. ,  315. ],\n",
            "         [1431. ,  315. ],\n",
            "         ...,\n",
            "         [1427. ,  588. ],\n",
            "         [1448. ,  676. ],\n",
            "         [1423. ,  667.5]],\n",
            "\n",
            "        [[1433. ,  321. ],\n",
            "         [1441. ,  312.5],\n",
            "         [1429. ,  312.5],\n",
            "         ...,\n",
            "         [1425. ,  588.5],\n",
            "         [1445. ,  676. ],\n",
            "         [1425. ,  668. ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 872. ,  323.5],\n",
            "         [ 867.5,  310.8],\n",
            "         [ 863.5,  310.8],\n",
            "         ...,\n",
            "         [ 855. ,  601.5],\n",
            "         [ 859. ,  678.5],\n",
            "         [ 850.5,  691.5]],\n",
            "\n",
            "        [[ 873. ,  323.2],\n",
            "         [ 868.5,  310.5],\n",
            "         [ 864.5,  314.8],\n",
            "         ...,\n",
            "         [ 856. ,  600. ],\n",
            "         [ 856. ,  676.5],\n",
            "         [ 851.5,  693.5]],\n",
            "\n",
            "        [[1005. ,  324.2],\n",
            "         [1014. ,  319.8],\n",
            "         [1009.5,  315.5],\n",
            "         ...,\n",
            "         [1045. ,  605.5],\n",
            "         [1049. ,  702. ],\n",
            "         [1058. ,  689. ]]],\n",
            "\n",
            "\n",
            "       [[[ 471.2,  325.8],\n",
            "         [ 471.2,  317. ],\n",
            "         [ 458.2,  317. ],\n",
            "         ...,\n",
            "         [ 466.8,  605. ],\n",
            "         [ 488.2,  678. ],\n",
            "         [ 471.2,  695. ]],\n",
            "\n",
            "        [[ 469.2,  327.8],\n",
            "         [ 473.5,  319.2],\n",
            "         [ 456.2,  319.2],\n",
            "         ...,\n",
            "         [ 464.8,  606. ],\n",
            "         [ 490.5,  678.5],\n",
            "         [ 473.5,  695.5]],\n",
            "\n",
            "        [[ 469.2,  327.8],\n",
            "         [ 473.5,  319.2],\n",
            "         [ 456.2,  319.2],\n",
            "         ...,\n",
            "         [ 464.8,  606. ],\n",
            "         [ 490.5,  678.5],\n",
            "         [ 473.5,  695.5]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1009. ,  322.5],\n",
            "         [1013.5,  318.2],\n",
            "         [1009. ,  318.2],\n",
            "         ...,\n",
            "         [1045. ,  606.5],\n",
            "         [1049. ,  699.5],\n",
            "         [1058. ,  690.5]],\n",
            "\n",
            "        [[1007. ,  326.8],\n",
            "         [1011.5,  317.8],\n",
            "         [1007. ,  317.8],\n",
            "         ...,\n",
            "         [1047. ,  603.5],\n",
            "         [1051. ,  700. ],\n",
            "         [1056. ,  691.5]],\n",
            "\n",
            "        [[ 874. ,  319. ],\n",
            "         [ 869.5,  310.5],\n",
            "         [ 861. ,  314.8],\n",
            "         ...,\n",
            "         [ 857. ,  600. ],\n",
            "         [ 857. ,  676.5],\n",
            "         [ 852.5,  689.5]]]], dtype=float16), 'keypoint_score': array([[[0.9204, 0.9204, 0.9136, ..., 0.879 , 0.8906, 0.9185],\n",
            "        [0.9487, 0.963 , 0.922 , ..., 0.8804, 0.9033, 0.9385],\n",
            "        [0.9175, 0.92  , 0.9204, ..., 0.8784, 0.8984, 0.923 ],\n",
            "        ...,\n",
            "        [0.9634, 0.914 , 0.9585, ..., 0.851 , 0.8496, 0.883 ],\n",
            "        [0.963 , 0.919 , 0.9497, ..., 0.851 , 0.866 , 0.8794],\n",
            "        [0.964 , 0.934 , 0.925 , ..., 0.8457, 0.8594, 0.895 ]],\n",
            "\n",
            "       [[0.9487, 0.9326, 0.929 , ..., 0.907 , 0.9106, 0.885 ],\n",
            "        [0.959 , 0.9307, 0.978 , ..., 0.915 , 0.898 , 0.9043],\n",
            "        [0.9536, 0.9336, 0.9775, ..., 0.916 , 0.9033, 0.9087],\n",
            "        ...,\n",
            "        [0.95  , 0.954 , 0.9214, ..., 0.856 , 0.847 , 0.8716],\n",
            "        [0.9536, 0.9272, 0.922 , ..., 0.836 , 0.859 , 0.8623],\n",
            "        [0.951 , 0.9355, 0.933 , ..., 0.8535, 0.8696, 0.8926]]],\n",
            "      dtype=float16)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_58_sample_keypoint = action_58_sample['keypoint']\n",
        "action_58_sample_keypoint_score = action_58_sample['keypoint_score']"
      ],
      "metadata": {
        "id": "gylN1cP97o1x"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyskl.datasets.pipelines.sampling import UniformSampleFrames\n",
        "\n",
        "# Initialize the sampler with desired parameters\n",
        "uniform_sample = UniformSampleFrames(clip_len=48, p_interval=1,num_clips=2, seed=255)\n",
        "\n",
        "# Assuming 'results' is a dictionary containing 'total_frames', 'start_index', etc.\n",
        "results = {\n",
        "    'total_frames': action_58_sample['total_frames'],  # Total number of frames in the video\n",
        "    'start_index': 0,  # Starting index for sampling\n",
        "    'test_mode': False,  # Indicating whether it's testing or training\n",
        "    'keypoint': action_58_sample['keypoint'],  # Including the 'keypoint' data\n",
        "    'keypoint_score': action_58_sample['keypoint_score'],  # Including the 'keypoint_score' data\n",
        "    'img_shape': (1080, 1920)\n",
        "}\n",
        "\n",
        "# Call the sampler to sample the frames\n",
        "processed_results = uniform_sample(results)\n",
        "\n",
        "# The processed results will contain the 'frame_inds' with the sampled frames\n",
        "print(processed_results['frame_inds'].shape)"
      ],
      "metadata": {
        "id": "Z6jStMwU7tJZ",
        "outputId": "84ec12e0-b758-4a30-b4ea-dacf1e566994",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyskl.datasets.pipelines.pose_related import PoseDecode\n",
        "# Create an instance of PoseDecode\n",
        "pose_decode = PoseDecode()\n",
        "\n",
        "# Apply PoseDecode on the results\n",
        "processed_results = pose_decode(processed_results)\n",
        "\n",
        "# Get the processed keypoints and keypoint scores for the selected frames\n",
        "selected_keypoints = processed_results['keypoint']  # Extracted keypoints for sampled frames\n",
        "selected_scores = processed_results['keypoint_score']  # Extracted keypoint scores for sampled frames\n",
        "\n",
        "# Print the output\n",
        "print(selected_keypoints.shape)  # (n_frames, 25, 2)\n",
        "print(selected_scores.shape)     # (n_frames, 25)"
      ],
      "metadata": {
        "id": "fzWY-xvZ8Kkh",
        "outputId": "c1d33ce8-3a7c-42f2-9f88-ea73a73a2d6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 96, 17, 2)\n",
            "(2, 96, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "coordinates = action_58_sample_keypoint\n",
        "confidence_scores = action_58_sample_keypoint_score\n",
        "\n",
        "# Assuming these are your original arrays\n",
        "coords = selected_keypoints  # Replace with actual data\n",
        "conf = selected_scores      # Replace with actual data\n",
        "\n",
        "# Transpose coordinates to (M, C, T, V)\n",
        "coords = np.transpose(coords, (0, 3, 1, 2))  # Shape: (2, 2, 99, 17)\n",
        "\n",
        "# Expand confidence scores to match dimensions (M, 1, T, V)\n",
        "conf = np.expand_dims(conf, axis=1)  # Shape: (2, 1, 99, 17)\n",
        "\n",
        "# Concatenate along the second axis (C)\n",
        "combined = np.concatenate((coords, conf), axis=1)  # Shape: (2, 3, 99, 17)\n",
        "\n",
        "# Swap M and last dimension (M should be last)\n",
        "combined = np.transpose(combined, (1, 2, 3, 0))  # Shape: (3, 99, 17, 2)\n",
        "\n",
        "# Add batch dimension (N=1)\n",
        "final_array = np.expand_dims(combined, axis=0)  # Shape: (1, 3, 99, 17, 2)\n",
        "\n",
        "print(final_array.shape)  # Expected Output: (1, 3, 99, 17, 2)\n",
        "print(final_array)\n",
        "\n",
        "x = final_array\n",
        "x.shape"
      ],
      "metadata": {
        "id": "39DGTZtS8t5Z",
        "outputId": "7b57de4f-813d-4bbc-cc6d-d43c9bd3ef43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 3, 96, 17, 2)\n",
            "[[[[[1.4330000e+03 4.7125000e+02]\n",
            "    [1.4410000e+03 4.7125000e+02]\n",
            "    [1.4290000e+03 4.5825000e+02]\n",
            "    ...\n",
            "    [1.4250000e+03 4.6675000e+02]\n",
            "    [1.4500000e+03 4.8825000e+02]\n",
            "    [1.4250000e+03 4.7125000e+02]]\n",
            "\n",
            "   [[1.4330000e+03 4.6925000e+02]\n",
            "    [1.4410000e+03 4.7350000e+02]\n",
            "    [1.4290000e+03 4.5625000e+02]\n",
            "    ...\n",
            "    [1.4250000e+03 4.6475000e+02]\n",
            "    [1.4450000e+03 4.9050000e+02]\n",
            "    [1.4250000e+03 4.7350000e+02]]\n",
            "\n",
            "   [[1.4330000e+03 4.6925000e+02]\n",
            "    [1.4410000e+03 4.7350000e+02]\n",
            "    [1.4290000e+03 4.5625000e+02]\n",
            "    ...\n",
            "    [1.4250000e+03 4.6475000e+02]\n",
            "    [1.4450000e+03 4.9050000e+02]\n",
            "    [1.4250000e+03 4.7350000e+02]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[8.6950000e+02 1.0095000e+03]\n",
            "    [8.6550000e+02 1.0185000e+03]\n",
            "    [8.5700000e+02 1.0140000e+03]\n",
            "    ...\n",
            "    [8.5700000e+02 1.0450000e+03]\n",
            "    [8.5700000e+02 1.0500000e+03]\n",
            "    [8.5250000e+02 1.0540000e+03]]\n",
            "\n",
            "   [[8.6850000e+02 1.0080000e+03]\n",
            "    [8.6850000e+02 1.0170000e+03]\n",
            "    [8.6000000e+02 1.0125000e+03]\n",
            "    ...\n",
            "    [8.5600000e+02 1.0440000e+03]\n",
            "    [8.5600000e+02 1.0520000e+03]\n",
            "    [8.5150000e+02 1.0570000e+03]]\n",
            "\n",
            "   [[8.7200000e+02 1.0090000e+03]\n",
            "    [8.6750000e+02 1.0135000e+03]\n",
            "    [8.6350000e+02 1.0090000e+03]\n",
            "    ...\n",
            "    [8.5500000e+02 1.0450000e+03]\n",
            "    [8.5900000e+02 1.0490000e+03]\n",
            "    [8.5050000e+02 1.0580000e+03]]]\n",
            "\n",
            "\n",
            "  [[[3.2100000e+02 3.2575000e+02]\n",
            "    [3.1250000e+02 3.1700000e+02]\n",
            "    [3.1250000e+02 3.1700000e+02]\n",
            "    ...\n",
            "    [5.8850000e+02 6.0500000e+02]\n",
            "    [6.7600000e+02 6.7800000e+02]\n",
            "    [6.6800000e+02 6.9500000e+02]]\n",
            "\n",
            "   [[3.2100000e+02 3.2775000e+02]\n",
            "    [3.1250000e+02 3.1925000e+02]\n",
            "    [3.1250000e+02 3.1925000e+02]\n",
            "    ...\n",
            "    [5.8850000e+02 6.0600000e+02]\n",
            "    [6.7600000e+02 6.7850000e+02]\n",
            "    [6.6800000e+02 6.9550000e+02]]\n",
            "\n",
            "   [[3.2275000e+02 3.2550000e+02]\n",
            "    [3.1425000e+02 3.2125000e+02]\n",
            "    [3.1025000e+02 3.2125000e+02]\n",
            "    ...\n",
            "    [5.8900000e+02 6.0350000e+02]\n",
            "    [6.7650000e+02 6.8050000e+02]\n",
            "    [6.6800000e+02 6.9350000e+02]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[3.1925000e+02 3.2475000e+02]\n",
            "    [3.1075000e+02 3.1575000e+02]\n",
            "    [3.1500000e+02 3.1575000e+02]\n",
            "    ...\n",
            "    [6.0150000e+02 6.0550000e+02]\n",
            "    [6.7850000e+02 6.9900000e+02]\n",
            "    [6.9150000e+02 6.9000000e+02]]\n",
            "\n",
            "   [[3.2325000e+02 3.2275000e+02]\n",
            "    [3.1050000e+02 3.1825000e+02]\n",
            "    [3.1475000e+02 3.1825000e+02]\n",
            "    ...\n",
            "    [6.0000000e+02 6.0350000e+02]\n",
            "    [6.7650000e+02 7.0150000e+02]\n",
            "    [6.9350000e+02 6.8800000e+02]]\n",
            "\n",
            "   [[3.2350000e+02 3.2250000e+02]\n",
            "    [3.1075000e+02 3.1825000e+02]\n",
            "    [3.1075000e+02 3.1825000e+02]\n",
            "    ...\n",
            "    [6.0150000e+02 6.0650000e+02]\n",
            "    [6.7850000e+02 6.9950000e+02]\n",
            "    [6.9150000e+02 6.9050000e+02]]]\n",
            "\n",
            "\n",
            "  [[[9.2041016e-01 9.4873047e-01]\n",
            "    [9.2041016e-01 9.3261719e-01]\n",
            "    [9.1357422e-01 9.2919922e-01]\n",
            "    ...\n",
            "    [8.7890625e-01 9.0722656e-01]\n",
            "    [8.9062500e-01 9.1064453e-01]\n",
            "    [9.1845703e-01 8.8476562e-01]]\n",
            "\n",
            "   [[9.1748047e-01 9.5361328e-01]\n",
            "    [9.1992188e-01 9.3359375e-01]\n",
            "    [9.2041016e-01 9.7753906e-01]\n",
            "    ...\n",
            "    [8.7841797e-01 9.1601562e-01]\n",
            "    [8.9843750e-01 9.0332031e-01]\n",
            "    [9.2285156e-01 9.0869141e-01]]\n",
            "\n",
            "   [[9.3408203e-01 9.1699219e-01]\n",
            "    [9.4873047e-01 9.1992188e-01]\n",
            "    [9.4628906e-01 9.4921875e-01]\n",
            "    ...\n",
            "    [8.7011719e-01 9.1113281e-01]\n",
            "    [8.9648438e-01 9.0478516e-01]\n",
            "    [9.1601562e-01 8.9794922e-01]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[9.8193359e-01 9.5556641e-01]\n",
            "    [9.6582031e-01 9.6972656e-01]\n",
            "    [9.7851562e-01 9.2919922e-01]\n",
            "    ...\n",
            "    [8.7158203e-01 8.6279297e-01]\n",
            "    [8.7060547e-01 9.1992188e-01]\n",
            "    [9.0722656e-01 8.4570312e-01]]\n",
            "\n",
            "   [[9.4531250e-01 9.7119141e-01]\n",
            "    [9.4726562e-01 9.3847656e-01]\n",
            "    [9.4042969e-01 9.2431641e-01]\n",
            "    ...\n",
            "    [8.4716797e-01 8.3056641e-01]\n",
            "    [8.6474609e-01 8.6181641e-01]\n",
            "    [8.8476562e-01 8.6523438e-01]]\n",
            "\n",
            "   [[9.6337891e-01 9.5019531e-01]\n",
            "    [9.1406250e-01 9.5410156e-01]\n",
            "    [9.5849609e-01 9.2138672e-01]\n",
            "    ...\n",
            "    [8.5107422e-01 8.5595703e-01]\n",
            "    [8.4960938e-01 8.4716797e-01]\n",
            "    [8.8281250e-01 8.7158203e-01]]]]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3, 96, 17, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numpy as geek  # (Do you really need this? 'geek' is another alias for numpy)\n",
        "from pyskl.datasets.pipelines.sampling import UniformSampleFrames\n",
        "from pyskl.datasets.pipelines.pose_related import PoseDecode\n",
        "\n",
        "\n",
        "all_videos_data = []\n",
        "\n",
        "# Loop through each annotation in data['annotations']\n",
        "for i, annotation in enumerate(data['annotations']):\n",
        "\n",
        "    if i >= 30:  # Stop after processing 30 videos\n",
        "        break\n",
        "\n",
        "    # Initialize the sampler with desired parameters\n",
        "    uniform_sample = UniformSampleFrames(clip_len=48, p_interval=1,num_clips=2, seed=255)\n",
        "\n",
        "    # Assuming 'results' is a dictionary containing 'total_frames', 'start_index', etc.\n",
        "    results = {\n",
        "    'total_frames': annotation['total_frames'],  # Total number of frames in the video\n",
        "    'start_index': 0,  # Starting index for sampling\n",
        "    'test_mode': False,  # Indicating whether it's testing or training\n",
        "    'keypoint': annotation['keypoint'],  # Including the 'keypoint' data\n",
        "    'keypoint_score': annotation['keypoint_score'],  # Including the 'keypoint_score' data\n",
        "    'img_shape': (1080, 1920)\n",
        "      }\n",
        "\n",
        "    # Call the sampler to sample the frames\n",
        "    processed_results = uniform_sample(results)\n",
        "\n",
        "    pose_decode = PoseDecode()\n",
        "\n",
        "    # Apply PoseDecode on the results\n",
        "    processed_results = pose_decode(processed_results)\n",
        "\n",
        "    # Get the processed keypoints and keypoint scores for the selected frames\n",
        "    #selected_keypoints = processed_results['keypoint']  # Extracted keypoints for sampled frames\n",
        "    #selected_scores = processed_results['keypoint_score']  # Extracted keypoint scores for sampled frames\n",
        "\n",
        "    coordinates = processed_results['keypoint']\n",
        "    confidence_scores = processed_results['keypoint_score']\n",
        "\n",
        "    # Assuming these are your original arrays\n",
        "    coords = coordinates  # Replace with actual data\n",
        "    conf = confidence_scores  # Replace with actual data\n",
        "\n",
        "\n",
        "\n",
        "    # Transpose coordinates to (M, C, T, V)\n",
        "    coords = np.transpose(coords, (0, 3, 1, 2))  # Shape: (2, 2, 99, 17)\n",
        "\n",
        "    # Expand confidence scores to match dimensions (M, 1, T, V)\n",
        "    conf = np.expand_dims(conf, axis=1)  # Shape: (2, 1, 99, 17)\n",
        "\n",
        "    # Concatenate along the second axis (C)\n",
        "    combined = np.concatenate((coords, conf), axis=1)  # Shape: (2, 3, 99, 17)\n",
        "\n",
        "    # Swap M and last dimension (M should be last)\n",
        "    combined = np.transpose(combined, (1, 2, 3, 0))  # Shape: (3, 99, 17, 2)\n",
        "\n",
        "    # Add batch dimension (N=1)\n",
        "    final_array = combined # Shape: (1, 3, 99, 17, 2)\n",
        "\n",
        "    all_videos_data.append(final_array)\n",
        "\n",
        "print(len(all_videos_data))\n",
        "\n",
        "#all_videos_data_np = np.array(all_videos_data)  # Convert list to NumPy array\n",
        "print(all_videos_data[29].shape)  # Check the shape of the array\n",
        "all_videos_data = np.array(all_videos_data)\n"
      ],
      "metadata": {
        "id": "-gal7C-O86Ob",
        "outputId": "f57793da-7ceb-4435-bd35-18ec76d6ed42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n",
            "(3, 96, 17, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_videos_data.shape"
      ],
      "metadata": {
        "id": "i-x9xDPZ-Dio",
        "outputId": "f92fca7e-b461-4570-c91b-9c5f5bdee982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 3, 96, 17, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_videos_data[0]"
      ],
      "metadata": {
        "id": "OjnXLb2UAHU6",
        "outputId": "fa241346-73d2-481d-db15-794780eccc11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[1.0320000e+03],\n",
              "         [1.0410000e+03],\n",
              "         [1.0235000e+03],\n",
              "         ...,\n",
              "         [1.0280000e+03],\n",
              "         [1.0630000e+03],\n",
              "         [1.0370000e+03]],\n",
              "\n",
              "        [[1.0320000e+03],\n",
              "         [1.0410000e+03],\n",
              "         [1.0230000e+03],\n",
              "         ...,\n",
              "         [1.0270000e+03],\n",
              "         [1.0630000e+03],\n",
              "         [1.0360000e+03]],\n",
              "\n",
              "        [[1.0320000e+03],\n",
              "         [1.0410000e+03],\n",
              "         [1.0235000e+03],\n",
              "         ...,\n",
              "         [1.0280000e+03],\n",
              "         [1.0630000e+03],\n",
              "         [1.0370000e+03]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1.0390000e+03],\n",
              "         [1.0480000e+03],\n",
              "         [1.0350000e+03],\n",
              "         ...,\n",
              "         [1.0300000e+03],\n",
              "         [1.0660000e+03],\n",
              "         [1.0390000e+03]],\n",
              "\n",
              "        [[1.0380000e+03],\n",
              "         [1.0470000e+03],\n",
              "         [1.0340000e+03],\n",
              "         ...,\n",
              "         [1.0290000e+03],\n",
              "         [1.0650000e+03],\n",
              "         [1.0380000e+03]],\n",
              "\n",
              "        [[1.0370000e+03],\n",
              "         [1.0500000e+03],\n",
              "         [1.0330000e+03],\n",
              "         ...,\n",
              "         [1.0280000e+03],\n",
              "         [1.0640000e+03],\n",
              "         [1.0370000e+03]]],\n",
              "\n",
              "\n",
              "       [[[3.3475000e+02],\n",
              "         [3.2575000e+02],\n",
              "         [3.2575000e+02],\n",
              "         ...,\n",
              "         [6.1150000e+02],\n",
              "         [7.0400000e+02],\n",
              "         [6.9500000e+02]],\n",
              "\n",
              "        [[3.3400000e+02],\n",
              "         [3.2500000e+02],\n",
              "         [3.2500000e+02],\n",
              "         ...,\n",
              "         [6.1250000e+02],\n",
              "         [7.0700000e+02],\n",
              "         [6.9800000e+02]],\n",
              "\n",
              "        [[3.3475000e+02],\n",
              "         [3.2575000e+02],\n",
              "         [3.2575000e+02],\n",
              "         ...,\n",
              "         [6.1150000e+02],\n",
              "         [7.0400000e+02],\n",
              "         [6.9500000e+02]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[3.2400000e+02],\n",
              "         [3.1525000e+02],\n",
              "         [3.1525000e+02],\n",
              "         ...,\n",
              "         [6.1550000e+02],\n",
              "         [7.0350000e+02],\n",
              "         [6.9500000e+02]],\n",
              "\n",
              "        [[3.2400000e+02],\n",
              "         [3.1525000e+02],\n",
              "         [3.1525000e+02],\n",
              "         ...,\n",
              "         [6.1100000e+02],\n",
              "         [7.0350000e+02],\n",
              "         [6.9500000e+02]],\n",
              "\n",
              "        [[3.2175000e+02],\n",
              "         [3.1750000e+02],\n",
              "         [3.1300000e+02],\n",
              "         ...,\n",
              "         [6.1200000e+02],\n",
              "         [7.0400000e+02],\n",
              "         [6.9550000e+02]]],\n",
              "\n",
              "\n",
              "       [[[9.3408203e-01],\n",
              "         [9.7656250e-01],\n",
              "         [9.7363281e-01],\n",
              "         ...,\n",
              "         [8.7597656e-01],\n",
              "         [8.8574219e-01],\n",
              "         [8.9208984e-01]],\n",
              "\n",
              "        [[9.5361328e-01],\n",
              "         [9.9365234e-01],\n",
              "         [9.8779297e-01],\n",
              "         ...,\n",
              "         [8.8671875e-01],\n",
              "         [9.0722656e-01],\n",
              "         [9.0283203e-01]],\n",
              "\n",
              "        [[9.2041016e-01],\n",
              "         [9.7802734e-01],\n",
              "         [9.7705078e-01],\n",
              "         ...,\n",
              "         [8.9062500e-01],\n",
              "         [8.9355469e-01],\n",
              "         [8.9160156e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[9.5898438e-01],\n",
              "         [9.4042969e-01],\n",
              "         [9.3750000e-01],\n",
              "         ...,\n",
              "         [8.9306641e-01],\n",
              "         [9.1406250e-01],\n",
              "         [9.1162109e-01]],\n",
              "\n",
              "        [[9.5410156e-01],\n",
              "         [9.2675781e-01],\n",
              "         [9.4970703e-01],\n",
              "         ...,\n",
              "         [8.9453125e-01],\n",
              "         [9.0478516e-01],\n",
              "         [8.9501953e-01]],\n",
              "\n",
              "        [[9.3652344e-01],\n",
              "         [9.0429688e-01],\n",
              "         [9.4140625e-01],\n",
              "         ...,\n",
              "         [8.9550781e-01],\n",
              "         [8.8818359e-01],\n",
              "         [9.0332031e-01]]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pyskl.datasets.pipelines.sampling import UniformSampleFrames\n",
        "from pyskl.datasets.pipelines.pose_related import PoseDecode\n",
        "\n",
        "allowed_actions = {\n",
        "    \"A050\", \"A051\", \"A052\", \"A053\", \"A054\", \"A055\", \"A056\", \"A057\",\n",
        "    \"A058\", \"A059\", \"A060\", \"A106\", \"A107\", \"A108\", \"A109\", \"A110\",\n",
        "    \"A111\", \"A112\", \"A113\", \"A114\", \"A115\", \"A116\", \"A117\", \"A118\",\n",
        "    \"A119\", \"A120\"\n",
        "}\n",
        "\n",
        "all_videos_data = []\n",
        "\n",
        "# Loop through each annotation in data['annotations']\n",
        "for annotation in data['annotations']:\n",
        "    frame_dir = annotation['frame_dir']\n",
        "    action_code = frame_dir[-4:]\n",
        "    #print(action_code)\n",
        "\n",
        "    if action_code not in allowed_actions:\n",
        "        continue\n",
        "\n",
        "    #print(annotation['frame_dir'] )\n",
        "\n",
        "    # Initialize the sampler with desired parameters\n",
        "    uniform_sample = UniformSampleFrames(clip_len=48, p_interval=1, num_clips=2, seed=255)\n",
        "\n",
        "    # Define the results dictionary\n",
        "    results = {\n",
        "        'total_frames': annotation['total_frames'],\n",
        "        'start_index': 0,\n",
        "        'test_mode': False,\n",
        "        'keypoint': annotation['keypoint'],\n",
        "        'keypoint_score': annotation['keypoint_score'],\n",
        "        'img_shape': (1080, 1920)\n",
        "    }\n",
        "\n",
        "    # Sample frames\n",
        "    processed_results = uniform_sample(results)\n",
        "\n",
        "    # Apply PoseDecode\n",
        "    pose_decode = PoseDecode()\n",
        "    processed_results = pose_decode(processed_results)\n",
        "\n",
        "    # Extract keypoints and confidence scores\n",
        "    coords = processed_results['keypoint']\n",
        "    conf = processed_results['keypoint_score']\n",
        "\n",
        "\n",
        "\n",
        "    # Transpose coordinates to (M, C, T, V)\n",
        "    coords = np.transpose(coords, (0, 3, 1, 2))  # Shape: (2, 2, 99, 17)\n",
        "\n",
        "    # Expand confidence scores to match dimensions (M, 1, T, V)\n",
        "    conf = np.expand_dims(conf, axis=1)  # Shape: (2, 1, 99, 17)\n",
        "\n",
        "    # Concatenate along the second axis (C)\n",
        "    combined = np.concatenate((coords, conf), axis=1)  # Shape: (2, 3, 99, 17)\n",
        "\n",
        "    # Swap M and last dimension (M should be last)\n",
        "    combined = np.transpose(combined, (1, 2, 3, 0))  # Shape: (3, 99, 17, 2)\n",
        "\n",
        "    # Add batch dimension (N=1)\n",
        "    final_array = combined # Shape: (1, 3, 99, 17, 2)\n",
        "\n",
        "    all_videos_data.append(final_array)\n",
        "\n",
        "     # Ensure fixed shape (T=96)\n",
        "    if len(all_videos_data) == 2100:\n",
        "        break  # Skip samples with different frame counts\n",
        "\n",
        "    #all_videos_data.append(combined)  # Append without extra batch dim\n",
        "\n",
        "all_videos_data = np.array(all_videos_data)\n",
        "print(all_videos_data.shape)\n",
        "type(all_videos_data)"
      ],
      "metadata": {
        "id": "CT_mK3IYDhPe",
        "outputId": "58764041-46ff-48d6-9385-d7679cf894c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2100, 3, 96, 17, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path\n",
        "folder_path = \"/content/drive/My Drive/zoom_transformer/data\"\n",
        "file_path = os.path.join(folder_path, \"NTU_mutual_actions_1000_videos.npy\")\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "# Save the NumPy array\n",
        "np.save(file_path, all_videos_data)\n",
        "\n",
        "print(f\"File saved at: {file_path}\")\n"
      ],
      "metadata": {
        "id": "BdXDYjrTG5B_",
        "outputId": "f5a8aa02-a55c-42a6-a2b9-2854ef61c3b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File saved at: /content/drive/My Drive/zoom_transformer/data/NTU_mutual_actions_1000_videos.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved NumPy array\n",
        "loaded_data = np.load(\"/content/drive/My Drive/zoom_transformer/data/NTU_mutual_actions_1000_videos.npy\")\n",
        "\n",
        "# Check the shape of the loaded data\n",
        "print(loaded_data.shape)  # Should be (2100, 3, 96, 17, 2)\n"
      ],
      "metadata": {
        "id": "Ardub2KPH09P",
        "outputId": "3d83c37e-1700-49e6-ab88-cf8f28adc729",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2100, 3, 96, 17, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from pyskl.datasets.pipelines.sampling import UniformSampleFrames\n",
        "from pyskl.datasets.pipelines.pose_related import PoseDecode\n",
        "\n",
        "# Define allowed actions\n",
        "allowed_actions = {\n",
        "    \"A050\", \"A051\", \"A052\", \"A053\", \"A054\", \"A055\", \"A056\", \"A057\",\n",
        "    \"A058\", \"A059\", \"A060\", \"A106\", \"A107\", \"A108\", \"A109\", \"A110\",\n",
        "    \"A111\", \"A112\", \"A113\", \"A114\", \"A115\", \"A116\", \"A117\", \"A118\",\n",
        "    \"A119\", \"A120\"\n",
        "}\n",
        "\n",
        "sample_names = []  # List to store sample names\n",
        "labels = []        # List to store corresponding labels\n",
        "\n",
        "all_videos_data = []  # List to store the processed data (keypoints, confidence scores, etc.)\n",
        "\n",
        "# Loop through each annotation in data['annotations']\n",
        "for i, annotation in enumerate(data['annotations']):\n",
        "    # Get the action class code from the frame directory (or another field)\n",
        "    frame_dir = annotation['frame_dir']\n",
        "    action_code = frame_dir[-4:]  # Assuming action code is the last 4 characters in frame_dir\n",
        "\n",
        "    # Skip the samples that are not in the allowed actions\n",
        "    if action_code not in allowed_actions:\n",
        "        continue\n",
        "\n",
        "    # Generate sample name dynamically\n",
        "    sample_name = f\"sample_{i+1}\"\n",
        "\n",
        "    # Extract the label for this sample\n",
        "    label = annotation['label']  # Assuming 'label' field exists in annotations\n",
        "\n",
        "    # Append to the lists\n",
        "    sample_names.append(sample_name)\n",
        "    labels.append(label)\n",
        "\n",
        "    # Stop at 2100 samples\n",
        "    if len(all_videos_data) == 2100:\n",
        "        break\n",
        "\n",
        "# Define the path for saving the pickle file\n",
        "pickle_filename = '/content/drive/My Drive/zoom_transformer/data/annotation_label.pkl'\n",
        "\n",
        "# Save the sample names and labels to the pickle file\n",
        "with open(pickle_filename, 'wb') as f:\n",
        "    pickle.dump((sample_names, labels), f)\n",
        "\n",
        "print(f\"Saved the pickle file with sample names and labels at: {pickle_filename}\")\n"
      ],
      "metadata": {
        "id": "19ogBItcKha0",
        "outputId": "8c9c1a1d-88d5-426f-b5d0-17f492cfc632",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved the pickle file with sample names and labels at: /content/drive/My Drive/zoom_transformer/data/annotation_label.pkl\n"
          ]
        }
      ]
    }
  ]
}