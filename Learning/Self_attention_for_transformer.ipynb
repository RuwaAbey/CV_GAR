{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiDnpDIA2zAKc1duGFuZrr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RuwaAbey/Finaly_Year_Project_G09/blob/main/Self_attention_for_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XcDrhL30BpfW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "L, d_k, d_v = 4, 8, 8\n",
        "q = np.random.randn(L, d_k)\n",
        "k = np.random.randn(L, d_k)\n",
        "v = np.random.randn(L, d_v)"
      ],
      "metadata": {
        "id": "18jihZ-nByXt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Q\\n\", q)\n",
        "print(\"K\\n\", k)\n",
        "print(\"V\\n\", v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQIAQT3RCHU1",
        "outputId": "b1b3d79c-cc10-43b2-d584-7768cde0b4d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q\n",
            " [[-1.46432704  0.20471281 -0.32898122  0.89483735  0.2242479   0.03151882\n",
            "  -0.29206521 -0.46967375]\n",
            " [ 1.10724791  0.34299864 -0.97608017  0.67612317 -0.90973631  0.2546449\n",
            "   0.34335394  0.21816381]\n",
            " [ 0.52143217  2.07134144  0.79366991 -0.94910141  0.3132216   0.90215894\n",
            "   0.12000727  1.18297572]\n",
            " [ 1.3669547   0.22876581 -0.98598411  0.96910186 -0.25485859 -1.49945397\n",
            "  -1.17463663 -0.65297544]]\n",
            "K\n",
            " [[-0.24670269  0.32929309  1.94359317 -0.14318404 -2.18338484  1.36615366\n",
            "  -0.90661051 -0.20062246]\n",
            " [-0.58742953  0.59282429  0.32258675 -1.44393185  1.11899284 -0.6023521\n",
            "  -0.37999452  0.01818678]\n",
            " [ 1.88333998 -1.66048334 -0.60445395  0.8263982   0.86080805  0.01275883\n",
            "   1.13997316 -1.94347608]\n",
            " [-0.26982031 -1.31406699  1.18463529  0.51031721 -0.56188925  1.2418082\n",
            "   0.03442553 -0.36791069]]\n",
            "V\n",
            " [[ 1.25869732 -1.55019724 -1.35622277  0.40265317 -1.43280593 -0.13594235\n",
            "  -0.92121947 -1.02116546]\n",
            " [-0.67461386 -0.36638122  0.44740676 -0.07170293  1.46450041 -0.30134998\n",
            "  -0.6201917   0.20893456]\n",
            " [ 0.06818796  0.46432045  0.80647389 -1.0477841  -0.34979269  1.0107372\n",
            "   1.37086607  1.4521356 ]\n",
            " [ 0.08994057 -0.64409209  1.73794655 -0.69805435 -0.48383808  1.50772494\n",
            "   0.21232556  1.03170477]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So here if I consider a sentence \"My name is Ruwa\" each work has got Q,K,V vector.\n",
        "\n",
        "So that size of each of the Q, K, V vectors is 4 x 8\n",
        "\n",
        "4 - number of words\n",
        "8 - number of elements used to represent the work\n",
        "\n"
      ],
      "metadata": {
        "id": "EMk-28agCU5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Self attention**\n",
        "\n",
        "$\\text{self-attention} = \\text{softmax} \\left( \\frac{QK^T}{\\sqrt{d_k}} + M \\right) V$\n"
      ],
      "metadata": {
        "id": "0ZGzAYJeDaW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.matmul(q, k.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5Ez0MuHCxlC",
        "outputId": "fd3e8180-d6f7-4841-b820-20ebb216b809"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.42641157, -0.08227377, -1.38611215,  0.26890831],\n",
              "       [-0.17499509, -3.03611772,  1.85208197, -0.80179638],\n",
              "       [ 2.43438041,  2.3310898 , -5.6026123 , -1.89349338],\n",
              "       [-2.61310299, -1.3322598 ,  3.28289693, -2.86196072]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This matrix represent how much each work is related other words.\n",
        "\n",
        "       My        | name            | is |Ruwa\n",
        "\n",
        "My   |-1.14929296|  2.62199025     |\n",
        "\n",
        "name |\n",
        "\n",
        "is   |\n",
        "\n",
        "Ruwa |"
      ],
      "metadata": {
        "id": "hfXCauCBEGWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#why we need sqrt(d_k) in denominator\n",
        "q.var(), k.var(), np.matmul(q, k.T).var() #checking varainces of Q,K and Q.KT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ystJ3gvY1Dgz",
        "outputId": "98a98d3d-2b8c-4781-bc53-daea1e56c229"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7308643072181876, 1.0855078221478214, 5.194239102626842)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled = np.matmul(q,k.T) / math.sqrt(d_k)\n",
        "q.var(), k.var(), scaled.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8aFofMD1Z-J",
        "outputId": "9c87a3f3-bd35-4ee3-f8c6-477a31df17ac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7308643072181876, 1.0855078221478214, 0.649279887828355)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the reduction in variance of the procut"
      ],
      "metadata": {
        "id": "6V4DTGUt1zfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uhe04EG1y8a",
        "outputId": "29bf4b28-128e-4b0e-9712-8502711c6410"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.15075926, -0.02908817, -0.49006465,  0.09507344],\n",
              "       [-0.06187011, -1.07342971,  0.65480986, -0.28347783],\n",
              "       [ 0.86068345,  0.8241647 , -1.98082258, -0.669451  ],\n",
              "       [-0.92387142, -0.47102497,  1.16067934, -1.01185592]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Masking**\n",
        "\n",
        "* This is to ensure words don't get context from words generated in the future\n",
        "\n",
        "* Not required in the encoders, but required int the decoders"
      ],
      "metadata": {
        "id": "40GOUtSe18FV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = np.tril(np.ones((L,L)))"
      ],
      "metadata": {
        "id": "JAmb0v5b2ODr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCRNq9r22WEN",
        "outputId": "45a57a4f-bc67-46e3-d8ca-3b7ab0ac84e3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [1., 1., 0., 0.],\n",
              "       [1., 1., 1., 0.],\n",
              "       [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask[mask == 0] = -np.infty\n",
        "mask[mask == 1] = 0"
      ],
      "metadata": {
        "id": "YmZnI1Nh2gJM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLOtyIVH2npm",
        "outputId": "9fd9d242-29bd-4d99-831e-1d6753feab1f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0., -inf, -inf, -inf],\n",
              "       [  0.,   0., -inf, -inf],\n",
              "       [  0.,   0.,   0., -inf],\n",
              "       [  0.,   0.,   0.,   0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled + mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySeXDTKG2XcM",
        "outputId": "fcbe8e30-0eab-4f2a-fe16-bdcc1b54fd57"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.15075926,        -inf,        -inf,        -inf],\n",
              "       [-0.06187011, -1.07342971,        -inf,        -inf],\n",
              "       [ 0.86068345,  0.8241647 , -1.98082258,        -inf],\n",
              "       [-0.92387142, -0.47102497,  1.16067934, -1.01185592]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "why negative infinty?\n",
        "\n",
        "* because of softmax operation\n"
      ],
      "metadata": {
        "id": "g-XvUWvg2qFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Softmax**  \n",
        "\n",
        "$\n",
        "\\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_j e^{x}_j}\n",
        "$\n"
      ],
      "metadata": {
        "id": "05FoxJ8I2yrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  return (np.exp(x).T / np.sum(np.exp(x), axis = 1)).T"
      ],
      "metadata": {
        "id": "-M1Miveo3oFw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention = softmax(scaled + mask)"
      ],
      "metadata": {
        "id": "JFaKxhsr6SIl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh2LY8Hd6W2N",
        "outputId": "677ca640-5c19-4d75-b22b-406655511e96"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.        , 0.        , 0.        ],\n",
              "       [0.73332526, 0.26667474, 0.        , 0.        ],\n",
              "       [0.49444301, 0.4767123 , 0.02884469, 0.        ],\n",
              "       [0.08673376, 0.13641335, 0.69742428, 0.07942861]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_without_mask = softmax(scaled)"
      ],
      "metadata": {
        "id": "PUuXPtHa6hFD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_without_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgoRLiEo6oJf",
        "outputId": "309378d4-f641-4ad0-afc4-fa827844651d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.24269882, 0.27409982, 0.17286585, 0.3103355 ],\n",
              "       [0.23738846, 0.08632664, 0.48608224, 0.19020266],\n",
              "       [0.44663109, 0.43061491, 0.02605545, 0.09669856],\n",
              "       [0.08673376, 0.13641335, 0.69742428, 0.07942861]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_v = np.matmul(attention, v)\n",
        "new_v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNQcfj_46vXe",
        "outputId": "801f0308-038d-4539-8d44-fffc70d9bb3d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.25869732, -1.55019724, -1.35622277,  0.40265317, -1.43280593,\n",
              "        -0.13594235, -0.92121947, -1.02116546],\n",
              "       [ 0.74313205, -1.2345034 , -0.87524033,  0.27615438, -0.6601675 ,\n",
              "        -0.18005239, -0.84094296, -0.69312885],\n",
              "       [ 0.30272423, -0.92774945, -0.43402808,  0.13468437, -0.02038519,\n",
              "        -0.18171859, -0.71160133, -0.36342005],\n",
              "       [ 0.071845  ,  0.08823529,  0.64389911, -0.76105317, -0.20687973,\n",
              "         0.77177021,  0.80843675,  1.03463344]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eZgoy6q67c3",
        "outputId": "af43bd52-836d-4d65-c023-5a30b17bb21e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.25869732, -1.55019724, -1.35622277,  0.40265317, -1.43280593,\n",
              "        -0.13594235, -0.92121947, -1.02116546],\n",
              "       [-0.67461386, -0.36638122,  0.44740676, -0.07170293,  1.46450041,\n",
              "        -0.30134998, -0.6201917 ,  0.20893456],\n",
              "       [ 0.06818796,  0.46432045,  0.80647389, -1.0477841 , -0.34979269,\n",
              "         1.0107372 ,  1.37086607,  1.4521356 ],\n",
              "       [ 0.08994057, -0.64409209,  1.73794655, -0.69805435, -0.48383808,\n",
              "         1.50772494,  0.21232556,  1.03170477]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "comapare before attention and after attention with v"
      ],
      "metadata": {
        "id": "XGUL7Hqu7CR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  return (np.exp(x).T/np.sum(np.exp(x), axis = -1)).T\n",
        "\n",
        "def scaled_dot_product_attention(q,k,v,mask=None):\n",
        "  d_k = q.shape[-1]\n",
        "  scaled = np.matmul(q,k.T) / math.sqrt(d_k)\n",
        "  if mask is not None:\n",
        "    scaled = scaled + mask\n",
        "  attention = softmax(scaled)\n",
        "  out = np.matmul(attention, v)\n",
        "  return out, attention\n"
      ],
      "metadata": {
        "id": "iduOEfd27ITo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values, attention = scaled_dot_product_attention(q,k,v, mask=None)\n",
        "print(\"Q\\n\", q)\n",
        "print(\"K\\n\", k)\n",
        "print(\"V\\n\", v)\n",
        "print(\"New\", values)\n",
        "print(\"Attention\", attention)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaIdmKFF8RJb",
        "outputId": "52aefaa8-01f0-4b2c-f683-b035b5535ac7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q\n",
            " [[-1.46432704  0.20471281 -0.32898122  0.89483735  0.2242479   0.03151882\n",
            "  -0.29206521 -0.46967375]\n",
            " [ 1.10724791  0.34299864 -0.97608017  0.67612317 -0.90973631  0.2546449\n",
            "   0.34335394  0.21816381]\n",
            " [ 0.52143217  2.07134144  0.79366991 -0.94910141  0.3132216   0.90215894\n",
            "   0.12000727  1.18297572]\n",
            " [ 1.3669547   0.22876581 -0.98598411  0.96910186 -0.25485859 -1.49945397\n",
            "  -1.17463663 -0.65297544]]\n",
            "K\n",
            " [[-0.24670269  0.32929309  1.94359317 -0.14318404 -2.18338484  1.36615366\n",
            "  -0.90661051 -0.20062246]\n",
            " [-0.58742953  0.59282429  0.32258675 -1.44393185  1.11899284 -0.6023521\n",
            "  -0.37999452  0.01818678]\n",
            " [ 1.88333998 -1.66048334 -0.60445395  0.8263982   0.86080805  0.01275883\n",
            "   1.13997316 -1.94347608]\n",
            " [-0.26982031 -1.31406699  1.18463529  0.51031721 -0.56188925  1.2418082\n",
            "   0.03442553 -0.36791069]]\n",
            "V\n",
            " [[ 1.25869732 -1.55019724 -1.35622277  0.40265317 -1.43280593 -0.13594235\n",
            "  -0.92121947 -1.02116546]\n",
            " [-0.67461386 -0.36638122  0.44740676 -0.07170293  1.46450041 -0.30134998\n",
            "  -0.6201917   0.20893456]\n",
            " [ 0.06818796  0.46432045  0.80647389 -1.0477841  -0.34979269  1.0107372\n",
            "   1.37086607  1.4521356 ]\n",
            " [ 0.08994057 -0.64409209  1.73794655 -0.69805435 -0.48383808  1.50772494\n",
            "   0.21232556  1.03170477]]\n",
            "New [[ 0.16027194 -0.59627557  0.47223875 -0.31968745 -0.15694036  0.52702949\n",
            "  -0.09070522  0.38063254]\n",
            " [ 0.29081496 -0.2964375   0.43924619 -0.5526857  -0.47576149  0.71978902\n",
            "   0.4345126   0.67771404]\n",
            " [ 0.28214836 -0.90032019 -0.22400127  0.05415974 -0.06520042 -0.01835184\n",
            "  -0.62225893 -0.22851349]\n",
            " [ 0.071845    0.08823529  0.64389911 -0.76105317 -0.20687973  0.77177021\n",
            "   0.80843675  1.03463344]]\n",
            "Attention [[0.24269882 0.27409982 0.17286585 0.3103355 ]\n",
            " [0.23738846 0.08632664 0.48608224 0.19020266]\n",
            " [0.44663109 0.43061491 0.02605545 0.09669856]\n",
            " [0.08673376 0.13641335 0.69742428 0.07942861]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values, attention = scaled_dot_product_attention(q,k,v, mask=mask)\n",
        "print(\"Q\\n\", q)\n",
        "print(\"K\\n\", k)\n",
        "print(\"V\\n\", v)\n",
        "print(\"New\", values)\n",
        "print(\"Attention\", attention)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKx3N1zE81N4",
        "outputId": "ccaa1c2e-e626-46be-f76a-2b2f9d507aac"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q\n",
            " [[-1.46432704  0.20471281 -0.32898122  0.89483735  0.2242479   0.03151882\n",
            "  -0.29206521 -0.46967375]\n",
            " [ 1.10724791  0.34299864 -0.97608017  0.67612317 -0.90973631  0.2546449\n",
            "   0.34335394  0.21816381]\n",
            " [ 0.52143217  2.07134144  0.79366991 -0.94910141  0.3132216   0.90215894\n",
            "   0.12000727  1.18297572]\n",
            " [ 1.3669547   0.22876581 -0.98598411  0.96910186 -0.25485859 -1.49945397\n",
            "  -1.17463663 -0.65297544]]\n",
            "K\n",
            " [[-0.24670269  0.32929309  1.94359317 -0.14318404 -2.18338484  1.36615366\n",
            "  -0.90661051 -0.20062246]\n",
            " [-0.58742953  0.59282429  0.32258675 -1.44393185  1.11899284 -0.6023521\n",
            "  -0.37999452  0.01818678]\n",
            " [ 1.88333998 -1.66048334 -0.60445395  0.8263982   0.86080805  0.01275883\n",
            "   1.13997316 -1.94347608]\n",
            " [-0.26982031 -1.31406699  1.18463529  0.51031721 -0.56188925  1.2418082\n",
            "   0.03442553 -0.36791069]]\n",
            "V\n",
            " [[ 1.25869732 -1.55019724 -1.35622277  0.40265317 -1.43280593 -0.13594235\n",
            "  -0.92121947 -1.02116546]\n",
            " [-0.67461386 -0.36638122  0.44740676 -0.07170293  1.46450041 -0.30134998\n",
            "  -0.6201917   0.20893456]\n",
            " [ 0.06818796  0.46432045  0.80647389 -1.0477841  -0.34979269  1.0107372\n",
            "   1.37086607  1.4521356 ]\n",
            " [ 0.08994057 -0.64409209  1.73794655 -0.69805435 -0.48383808  1.50772494\n",
            "   0.21232556  1.03170477]]\n",
            "New [[ 1.25869732 -1.55019724 -1.35622277  0.40265317 -1.43280593 -0.13594235\n",
            "  -0.92121947 -1.02116546]\n",
            " [ 0.74313205 -1.2345034  -0.87524033  0.27615438 -0.6601675  -0.18005239\n",
            "  -0.84094296 -0.69312885]\n",
            " [ 0.30272423 -0.92774945 -0.43402808  0.13468437 -0.02038519 -0.18171859\n",
            "  -0.71160133 -0.36342005]\n",
            " [ 0.071845    0.08823529  0.64389911 -0.76105317 -0.20687973  0.77177021\n",
            "   0.80843675  1.03463344]]\n",
            "Attention [[1.         0.         0.         0.        ]\n",
            " [0.73332526 0.26667474 0.         0.        ]\n",
            " [0.49444301 0.4767123  0.02884469 0.        ]\n",
            " [0.08673376 0.13641335 0.69742428 0.07942861]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No word get any attention form the words that come after it. (in this created mask)"
      ],
      "metadata": {
        "id": "XmIsancE85Ty"
      }
    }
  ]
}